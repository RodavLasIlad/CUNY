
# coding: utf-8

# In[1]:

import csv
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import pandas as ps
import datetime


# In[2]:

rkd = ps.read_csv('C:\\Users\\Brett\\Documents\\Data\\riverkeeper_data_2013.csv')


# In[3]:

rkd['Date'] = ps.Series([ps.to_datetime(x) for x in rkd['Date']])


# Converting anything that is 'less than' or 'greater than' for the Entero Data to just that number. (i.e. <10 becomes 10)

# In[4]:

for i in range(len(rkd['EnteroCount'])):
    if not rkd['EnteroCount'][i].isdigit():
        rkd['EnteroCount'][i] = rkd['EnteroCount'][i][1:]


# In[5]:

rkd['EnteroCount'] = rkd['EnteroCount'].convert_objects(convert_numeric=True)


# #1
# First let's get a feel for the data: (as per the class examples)

# In[8]:

get_ipython().magic(u'matplotlib inline')
rkd['unit'] = 'Entero Count'
sns.tsplot(rkd.reset_index(), 
           time="index", 
           unit="unit",
           value="EnteroCount",
           color="indianred",
           interpolate=False)


# We can see a pretty clear ceiling at 25000, but also a cutaway at 2500--these were generated by how I cleaned the data (removing the greater than/less than signs) but they still give us a good estimation of how the data looks. Let's try a boxplot by site

# In[9]:

sns.factorplot(x='Site', y='EnteroCount', data=rkd, kind='bar')


# While the tet is completely useless, we can clearly see that the ranges are very large (judging by the hugh grey bars that show the quantiles) but that there are still some sites with significantly higher Enterocounts. Let's trying something more useful, like graphing those sites that average more than a thousand in the Enterocount (and would thus be reliably bad places for a swim).

# In[10]:

bysite = rkd.groupby('Site')
bysiteHigh = bysite.filter(lambda x: x['EnteroCount'].mean() > 1000)
sns.factorplot(x='Site', y='EnteroCount', data=bysiteHigh, kind='bar')
plt.xticks(rotation=90)


# In[11]:

bysiteHigh.groupby('Site').mean()


# We can also choose not to swim by finding all the locations that had very high levels in any sample (as it may be badly polluted on a given day, but low on others--still likely not worth the risk). We can also see that some bodies of water are only affected in certain parts (which is rather unsurprising, as those upstream of a sewage runoff would not be effected by the downstream sewage flow).

# In[12]:

bysiteMax = bysite.max()
bysiteMax.query('EnteroCount >= 24196')


# Now that we've seen some of the worst, let's take a look at the sites that would be pretty safe to swim at (judging by the Entero count).

# In[13]:

bysiteLow = bysite.filter(lambda x: x['EnteroCount'].mean() < 50)
sns.factorplot(x='Site', y='EnteroCount', data=bysiteLow, kind='bar')
plt.xticks(rotation=90)


# So we have quite a few to choose from, but we might want to avoid some that have high quantiles (such as Norrie Point mid-channel and 79th street, mid-channel). $$$$
# We know that we converted those that were <1 to just one, and we can evaluate those here:

# In[14]:

bysiteMin = bysite.min()
bysiteMin.query('EnteroCount <= 1')


# We can see that these sites are pretty safe, sometimes having essentially no detectable bacteria (although a great assumption cannot be made from an n=1 sample, which these represent) but on the given date and site, there would have been virtually no chance of anyone getting sick from the water)

# #2
# Now lets look at how regularly the tests have been performed, starting with a general plot to get an idea.

# In[16]:

sns.factorplot(x='Site', y='SampleCount', data=rkd, kind='bar')


# Again, the text here is not necessary, but we can get an idea of how frequently different sites are sampled (and that there are some clear outliers). $$$$
# Now lets look at the frequently sampled (more than 50 times):

# In[24]:

oftenSampled = bysite.filter(lambda x: x['SampleCount'] > 50)
sns.barplot(x='Site', y='SampleCount', data=oftenSampled)
plt.xticks(rotation=90)


# Piermont Pier and Upper Sparkill creek clearly have significantly more samples than any of the others (and are outliers), but there are still some that are sample much more often.

# In[430]:

seldomSampled = bysite.filter(lambda x: x['SampleCount'] <= 35)
sns.factorplot(x='Site', y='SampleCount', data=seldomSampled, kind='bar')
plt.xticks(rotation=90)


# 35 seems like a floor except for Tarrytown Marina, which has been sampled less than thirty times).$$$$
# We now know the max is close to 200, and the minimum is close to 30.$$$$
# Now lets find out which sites go the longest between samples:

# In[17]:

allsites = list(set(rkd['Site']))


# In[18]:

datesMaxes = []
for i in range(len(allsites)):
    currsite = rkd[rkd['Site'] == allsites[i]].sort(columns='Date')
    rowiterator = currsite.iterrows()
    datesl = []
    siteMax = datetime.timedelta(days=0)
    for j, row in rowiterator:
        datesl.append(row['Date'])
    for j in range(len(datesl) - 1):
        if -1 * (datesl[j] - datesl[j+1]) > siteMax:
            siteMax = -1 * (datesl[j] - datesl[j+1])
    temp = [allsites[i], siteMax]
    datesMaxes.append(temp)
dateMaxes = ps.DataFrame(datesMaxes)
dateMaxes.columns = ['Site', 'MaxDays']


# In[19]:

dateMaxes
highDays = dateMaxes[dateMaxes['MaxDays'] > np.timedelta64(250, 'D')]


# The ones that are sampled the most often:

# In[21]:

highDays


# In[22]:

g = sns.barplot(highDays['Site'], highDays['MaxDays'].astype('timedelta64[D]'))
g.set(ylim=(220, None))
plt.xticks(rotation=90)


# There are clearly some sites that are sampled significantly less often than others, especially the Tarrytown Marina (which is insurprising, given its low overall sample rate) but also the Gowanus Canal, which means that the fact that it has the highest mean is not necessarily reflective (it may only have been studied on bad days).

# #3
# Rain and water quality

# In[25]:

sns.lmplot(y='EnteroCount', x='FourDayRainTotal', data=rkd)


# We can see that it seems that the more rain there is, the higher the mean Entero Count is (possibly because of the runoff created by the water). Let's use our oftenSampled data set to compare.

# In[437]:

sns.lmplot(y='EnteroCount', x='FourDayRainTotal', hue='Site', data=oftenSampled)


# We can see that the more it rains, the more Entero we generall encounter (although at some sites it's less). In the ones it's slight less at, this is likely because there is no fecal matter to run off, and thus the water is just diluted by the rain.

# In[438]:

rkd['FourDayRainTotal'].describe()


# In[439]:

lotsofrain = bysite.filter(lambda x: x['FourDayRainTotal'] >= 1.57)
lotrset = set(lotsofrain['Site'])


# In[440]:

littlerain = bysite.filter(lambda x: x['FourDayRainTotal'] == 0)
litrset = set(littlerain['Site'])


# Those with a lot of rain (more than a full standard deviation above the mean):

# In[441]:

lotrall = rkd[rkd['Site'].isin(lotrset)]
sns.lmplot(y='EnteroCount', x='FourDayRainTotal', data=lotrall)


# Those with zero rain in the past four days:

# In[442]:

litrall = rkd[rkd['Site'].isin(litrset)]
sns.lmplot(y='EnteroCount', x='FourDayRainTotal', data=litrall)


# We can see that both those with a lot of rain and a little bit of rain have a higher entero count the more it rains, but that it varies widely in places with a lot of rain (possibly more potential if the bacteria is local for it to breed)--we saw that most of our highest values had 8.5 or more inches of rain in the past four days, but not as widely in places with a little bit of rain (but that there are significantly more outliers)
